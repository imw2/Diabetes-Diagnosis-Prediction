{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>expire_flag</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>elix_score</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_encoded</th>\n",
       "      <th>glucose_readings</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137275</td>\n",
       "      <td>9319</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>12</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>118.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101422</td>\n",
       "      <td>71582</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>106.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>148291</td>\n",
       "      <td>9299</td>\n",
       "      <td>0</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>-2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>222.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>116534</td>\n",
       "      <td>46467</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>133497</td>\n",
       "      <td>20374</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  subject_id  expire_flag admission_type  elix_score  age  \\\n",
       "0   137275        9319            0       ELECTIVE          12   82   \n",
       "3   101422       71582            0      EMERGENCY           0   76   \n",
       "5   148291        9299            0      EMERGENCY          -2   62   \n",
       "6   116534       46467            0       ELECTIVE          13   82   \n",
       "8   133497       20374            0       ELECTIVE          15   56   \n",
       "\n",
       "   admission_type_encoded  glucose_readings      0      1  ...        6  \\\n",
       "0                       0                45  118.0   97.0  ...     93.0   \n",
       "3                       1                21  106.0  134.0  ...    115.0   \n",
       "5                       1                28  222.0  128.0  ...    120.0   \n",
       "6                       0                37  235.0  235.0  ...     78.0   \n",
       "8                       0                28   89.0   89.0  ...     74.0   \n",
       "\n",
       "       7      8      9     10     11     12     13     14  range  \n",
       "0   93.0  109.0  109.0   94.0   94.0   98.0   98.0   85.0   82.0  \n",
       "3  114.0  159.0  161.0   90.0  113.0  113.0  148.0  139.0   88.0  \n",
       "5  106.0  106.0   97.0  137.0  126.0  107.0  111.0  111.0  145.0  \n",
       "6   84.0   99.0   76.0  114.0  152.0  202.0  262.0  304.0  228.0  \n",
       "8   74.0   87.0   93.0   83.0    0.0   97.0   94.0   94.0  122.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('finalDF.csv',index_col=0)\n",
    "df = df.drop(columns=['glucose'])\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = df[df.expire_flag==0]\n",
    "df_minority = df[df.expire_flag==1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,   \n",
    "                                 n_samples=7436,     \n",
    "                                 random_state=123) \n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14872, 24)\n",
      "[[12 85 1 ... 169.0 169.0 105.0]\n",
      " [19 56 1 ... 71.0 99.0 194.0]\n",
      " [7 72 1 ... 105.0 129.0 219.0]\n",
      " ...\n",
      " [12 49 1 ... 75.0 76.0 171.0]\n",
      " [25 65 1 ... 295.0 303.0 283.0]\n",
      " [10 63 1 ... 297.0 413.0 340.0]]\n"
     ]
    }
   ],
   "source": [
    "pydf = df_upsampled.values\n",
    "print(pydf.shape)\n",
    "X = pydf[:,4:24]\n",
    "y = df_upsampled['expire_flag']\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#X = scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def mortality_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14, input_dim=20, activation='relu'))\n",
    "    model.add(Dense(7,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = KerasClassifier(build_fn=mortality_model,epochs=50,batch_size=32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10744/10744 [==============================] - 1s 63us/step - loss: 1.0956 - acc: 0.4990\n",
      "Epoch 2/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6941 - acc: 0.4990\n",
      "Epoch 3/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6920 - acc: 0.4996\n",
      "Epoch 4/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6921 - acc: 0.5012\n",
      "Epoch 5/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6915 - acc: 0.5019\n",
      "Epoch 6/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6912 - acc: 0.5032\n",
      "Epoch 7/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6911 - acc: 0.5080\n",
      "Epoch 8/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6893 - acc: 0.5165\n",
      "Epoch 9/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6887 - acc: 0.5186\n",
      "Epoch 10/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6859 - acc: 0.5199\n",
      "Epoch 11/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6870 - acc: 0.5170\n",
      "Epoch 12/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6875 - acc: 0.5165\n",
      "Epoch 13/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6864 - acc: 0.5218\n",
      "Epoch 14/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6854 - acc: 0.5220\n",
      "Epoch 15/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6838 - acc: 0.5310\n",
      "Epoch 16/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6818 - acc: 0.5602\n",
      "Epoch 17/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6774 - acc: 0.5758\n",
      "Epoch 18/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6738 - acc: 0.5914\n",
      "Epoch 19/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6703 - acc: 0.5930\n",
      "Epoch 20/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6685 - acc: 0.5964\n",
      "Epoch 21/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6620 - acc: 0.6094\n",
      "Epoch 22/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6585 - acc: 0.6166\n",
      "Epoch 23/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6552 - acc: 0.6212\n",
      "Epoch 24/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6533 - acc: 0.6237\n",
      "Epoch 25/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6476 - acc: 0.6362\n",
      "Epoch 26/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6455 - acc: 0.6345\n",
      "Epoch 27/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6433 - acc: 0.6346\n",
      "Epoch 28/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6438 - acc: 0.6372\n",
      "Epoch 29/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6394 - acc: 0.6380\n",
      "Epoch 30/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6371 - acc: 0.6431\n",
      "Epoch 31/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6358 - acc: 0.6461\n",
      "Epoch 32/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6324 - acc: 0.6506\n",
      "Epoch 33/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6337 - acc: 0.6486\n",
      "Epoch 34/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6314 - acc: 0.6511\n",
      "Epoch 35/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6276 - acc: 0.6551\n",
      "Epoch 36/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6265 - acc: 0.6557\n",
      "Epoch 37/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6202 - acc: 0.6613\n",
      "Epoch 38/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6222 - acc: 0.6593\n",
      "Epoch 39/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6188 - acc: 0.6616\n",
      "Epoch 40/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6186 - acc: 0.6649\n",
      "Epoch 41/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6201 - acc: 0.6623\n",
      "Epoch 42/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6163 - acc: 0.6647\n",
      "Epoch 43/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6146 - acc: 0.6670\n",
      "Epoch 44/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6111 - acc: 0.6700\n",
      "Epoch 45/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6122 - acc: 0.6668\n",
      "Epoch 46/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6080 - acc: 0.6708\n",
      "Epoch 47/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6132 - acc: 0.6666\n",
      "Epoch 48/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6074 - acc: 0.6727\n",
      "Epoch 49/50\n",
      "10744/10744 [==============================] - 0s 24us/step - loss: 0.6048 - acc: 0.6723\n",
      "Epoch 50/50\n",
      "10744/10744 [==============================] - 0s 23us/step - loss: 0.6087 - acc: 0.6720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ecf2b20400>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7162/7162 [==============================] - 1s 133us/step - loss: 1.3918 - acc: 0.5505\n",
      "Epoch 2/5\n",
      "7162/7162 [==============================] - 0s 69us/step - loss: 0.7186 - acc: 0.5553\n",
      "Epoch 3/5\n",
      "7162/7162 [==============================] - 0s 69us/step - loss: 0.7000 - acc: 0.5602\n",
      "Epoch 4/5\n",
      "7162/7162 [==============================] - 0s 68us/step - loss: 0.6963 - acc: 0.5635\n",
      "Epoch 5/5\n",
      "7162/7162 [==============================] - 0s 69us/step - loss: 0.6865 - acc: 0.5829\n",
      "3582/3582 [==============================] - 0s 72us/step\n",
      "7162/7162 [==============================] - 0s 35us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 135us/step - loss: 0.8827 - acc: 0.4775\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 1s 73us/step - loss: 0.6913 - acc: 0.5329\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 1s 71us/step - loss: 0.6820 - acc: 0.5840\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 70us/step - loss: 0.6758 - acc: 0.5912\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 1s 70us/step - loss: 0.6716 - acc: 0.5985\n",
      "3581/3581 [==============================] - 0s 98us/step\n",
      "7163/7163 [==============================] - 0s 38us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 143us/step - loss: 1.1000 - acc: 0.5151\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 1s 73us/step - loss: 0.7126 - acc: 0.5334\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 1s 72us/step - loss: 0.6890 - acc: 0.5713\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 1s 74us/step - loss: 0.6809 - acc: 0.5823\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 1s 71us/step - loss: 0.6758 - acc: 0.5897\n",
      "3581/3581 [==============================] - 0s 79us/step\n",
      "7163/7163 [==============================] - 0s 39us/step\n",
      "Epoch 1/10\n",
      "7162/7162 [==============================] - 1s 156us/step - loss: 4.2118 - acc: 0.5377\n",
      "Epoch 2/10\n",
      "7162/7162 [==============================] - 1s 78us/step - loss: 1.4554 - acc: 0.5829: 0s - loss: 2.0110 - a\n",
      "Epoch 3/10\n",
      "7162/7162 [==============================] - 1s 80us/step - loss: 0.8358 - acc: 0.6205\n",
      "Epoch 4/10\n",
      "7162/7162 [==============================] - 1s 95us/step - loss: 0.7398 - acc: 0.6190\n",
      "Epoch 5/10\n",
      "7162/7162 [==============================] - 1s 90us/step - loss: 0.6800 - acc: 0.6340\n",
      "Epoch 6/10\n",
      "7162/7162 [==============================] - 1s 90us/step - loss: 0.6762 - acc: 0.6322\n",
      "Epoch 7/10\n",
      "7162/7162 [==============================] - 1s 90us/step - loss: 0.6688 - acc: 0.6349: 0s - loss: 0.6479 - a\n",
      "Epoch 8/10\n",
      "7162/7162 [==============================] - 1s 80us/step - loss: 0.6596 - acc: 0.6420\n",
      "Epoch 9/10\n",
      "7162/7162 [==============================] - 1s 81us/step - loss: 0.6464 - acc: 0.6534\n",
      "Epoch 10/10\n",
      "7162/7162 [==============================] - 1s 86us/step - loss: 0.6403 - acc: 0.6554\n",
      "3582/3582 [==============================] - 0s 93us/step\n",
      "7162/7162 [==============================] - 0s 41us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 1s 172us/step - loss: 1.5079 - acc: 0.5178\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 1s 82us/step - loss: 0.7455 - acc: 0.5241\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 1s 82us/step - loss: 0.7291 - acc: 0.5348\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 1s 81us/step - loss: 0.7187 - acc: 0.5383\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 1s 81us/step - loss: 0.7063 - acc: 0.5421\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 1s 91us/step - loss: 0.6980 - acc: 0.5545\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 1s 85us/step - loss: 0.6918 - acc: 0.5699\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 1s 87us/step - loss: 0.6834 - acc: 0.5796\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 1s 85us/step - loss: 0.6732 - acc: 0.6071\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 1s 90us/step - loss: 0.6582 - acc: 0.6266\n",
      "3581/3581 [==============================] - 0s 98us/step\n",
      "7163/7163 [==============================] - 0s 42us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 1s 187us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 1s 91us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 1s 89us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 1s 91us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 1s 90us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 1s 84us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 1s 85us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 1s 82us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 1s 82us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 1s 82us/step - loss: 8.0287 - acc: 0.5019: 0s - loss: 8.5875 - \n",
      "3581/3581 [==============================] - 0s 106us/step\n",
      "7163/7163 [==============================] - 0s 44us/step\n",
      "Epoch 1/50\n",
      "7162/7162 [==============================] - 1s 182us/step - loss: 1.4411 - acc: 0.5112\n",
      "Epoch 2/50\n",
      "7162/7162 [==============================] - 1s 81us/step - loss: 0.7265 - acc: 0.5441\n",
      "Epoch 3/50\n",
      "7162/7162 [==============================] - 1s 87us/step - loss: 0.7110 - acc: 0.5369\n",
      "Epoch 4/50\n",
      "7162/7162 [==============================] - 1s 91us/step - loss: 0.7050 - acc: 0.5423\n",
      "Epoch 5/50\n",
      "7162/7162 [==============================] - 1s 91us/step - loss: 0.7043 - acc: 0.5207\n",
      "Epoch 6/50\n",
      "7162/7162 [==============================] - 1s 90us/step - loss: 0.7027 - acc: 0.5219\n",
      "Epoch 7/50\n",
      "7162/7162 [==============================] - 1s 88us/step - loss: 0.7033 - acc: 0.5070: 0s - loss: 0.7002 - \n",
      "Epoch 8/50\n",
      "7162/7162 [==============================] - 1s 86us/step - loss: 0.7003 - acc: 0.5008\n",
      "Epoch 9/50\n",
      "7162/7162 [==============================] - 1s 87us/step - loss: 0.6989 - acc: 0.5087\n",
      "Epoch 10/50\n",
      "7162/7162 [==============================] - 1s 85us/step - loss: 0.6988 - acc: 0.4951\n",
      "Epoch 11/50\n",
      "7162/7162 [==============================] - 1s 80us/step - loss: 0.7008 - acc: 0.5077\n",
      "Epoch 12/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6998 - acc: 0.5073\n",
      "Epoch 13/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.7027 - acc: 0.5110\n",
      "Epoch 14/50\n",
      "7162/7162 [==============================] - 1s 81us/step - loss: 0.6972 - acc: 0.5091\n",
      "Epoch 15/50\n",
      "7162/7162 [==============================] - 1s 78us/step - loss: 0.6965 - acc: 0.4983\n",
      "Epoch 16/50\n",
      "7162/7162 [==============================] - 1s 81us/step - loss: 0.6964 - acc: 0.5034\n",
      "Epoch 17/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6958 - acc: 0.5182\n",
      "Epoch 18/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6951 - acc: 0.5134\n",
      "Epoch 19/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6897 - acc: 0.5205\n",
      "Epoch 20/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6867 - acc: 0.5334\n",
      "Epoch 21/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6818 - acc: 0.5342\n",
      "Epoch 22/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6816 - acc: 0.5451\n",
      "Epoch 23/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6804 - acc: 0.5694\n",
      "Epoch 24/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6686 - acc: 0.5838\n",
      "Epoch 25/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6679 - acc: 0.5870\n",
      "Epoch 26/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6686 - acc: 0.5945\n",
      "Epoch 27/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6659 - acc: 0.5998\n",
      "Epoch 28/50\n",
      "7162/7162 [==============================] - 1s 77us/step - loss: 0.6607 - acc: 0.6127\n",
      "Epoch 29/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6544 - acc: 0.6213\n",
      "Epoch 30/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6522 - acc: 0.6250\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6479 - acc: 0.6350\n",
      "Epoch 32/50\n",
      "7162/7162 [==============================] - 1s 77us/step - loss: 0.6517 - acc: 0.6231\n",
      "Epoch 33/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6470 - acc: 0.6289\n",
      "Epoch 34/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6392 - acc: 0.6396\n",
      "Epoch 35/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6370 - acc: 0.6481\n",
      "Epoch 36/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6369 - acc: 0.6456\n",
      "Epoch 37/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6342 - acc: 0.6438\n",
      "Epoch 38/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6344 - acc: 0.6361\n",
      "Epoch 39/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6309 - acc: 0.6518\n",
      "Epoch 40/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6259 - acc: 0.6574\n",
      "Epoch 41/50\n",
      "7162/7162 [==============================] - 1s 76us/step - loss: 0.6241 - acc: 0.6592\n",
      "Epoch 42/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6259 - acc: 0.6516\n",
      "Epoch 43/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6202 - acc: 0.6636\n",
      "Epoch 44/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6176 - acc: 0.6659\n",
      "Epoch 45/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6170 - acc: 0.6671\n",
      "Epoch 46/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6143 - acc: 0.6722\n",
      "Epoch 47/50\n",
      "7162/7162 [==============================] - 1s 79us/step - loss: 0.6142 - acc: 0.6716\n",
      "Epoch 48/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6093 - acc: 0.6733\n",
      "Epoch 49/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6101 - acc: 0.6780\n",
      "Epoch 50/50\n",
      "7162/7162 [==============================] - 1s 75us/step - loss: 0.6077 - acc: 0.6716\n",
      "3582/3582 [==============================] - 0s 101us/step\n",
      "7162/7162 [==============================] - 0s 45us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 168us/step - loss: 6.2214 - acc: 0.5108\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.7062 - acc: 0.5020\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.6914 - acc: 0.5323\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6798 - acc: 0.5884\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6654 - acc: 0.6091\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6593 - acc: 0.6187\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6520 - acc: 0.6344\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6429 - acc: 0.6439\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.6291 - acc: 0.6633\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6226 - acc: 0.6677\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.6102 - acc: 0.6796\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6041 - acc: 0.6850\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5987 - acc: 0.6883\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5961 - acc: 0.6884\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5932 - acc: 0.6915\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5912 - acc: 0.6938\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5892 - acc: 0.6994\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5856 - acc: 0.6965\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5829 - acc: 0.6980\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5831 - acc: 0.7011\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5801 - acc: 0.7060\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5786 - acc: 0.7038\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5767 - acc: 0.7005\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5733 - acc: 0.7085\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5738 - acc: 0.7032\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5715 - acc: 0.7103\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 1s 75us/step - loss: 0.5679 - acc: 0.7123\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5686 - acc: 0.7089\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5685 - acc: 0.7114\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5659 - acc: 0.7184\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5628 - acc: 0.7162\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5638 - acc: 0.7088\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5611 - acc: 0.7166\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5600 - acc: 0.7142\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5583 - acc: 0.7159\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5595 - acc: 0.7163\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5591 - acc: 0.7190\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5592 - acc: 0.7128\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 1s 75us/step - loss: 0.5551 - acc: 0.7208\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5556 - acc: 0.7204\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 1s 75us/step - loss: 0.5541 - acc: 0.7211\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5536 - acc: 0.7247\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 1s 75us/step - loss: 0.5523 - acc: 0.7201\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5519 - acc: 0.7195\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5528 - acc: 0.7261\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5526 - acc: 0.7251\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5503 - acc: 0.7275\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 1s 75us/step - loss: 0.5476 - acc: 0.7292\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5459 - acc: 0.7299\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.5468 - acc: 0.7278\n",
      "3581/3581 [==============================] - 0s 106us/step\n",
      "7163/7163 [==============================] - 0s 42us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 177us/step - loss: 4.9861 - acc: 0.5590\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.8685 - acc: 0.5485\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.7486 - acc: 0.5446\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.7064 - acc: 0.5749\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6905 - acc: 0.5820\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6731 - acc: 0.6052\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6625 - acc: 0.6179\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.6505 - acc: 0.6362\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6372 - acc: 0.6514\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.6258 - acc: 0.6623\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6210 - acc: 0.6642\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6148 - acc: 0.6697\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6168 - acc: 0.6704\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6076 - acc: 0.6722\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6059 - acc: 0.6767\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.6014 - acc: 0.6818\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 1s 76us/step - loss: 0.6031 - acc: 0.6850\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5970 - acc: 0.6813\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5952 - acc: 0.6855\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5953 - acc: 0.6926\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5918 - acc: 0.6873\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5918 - acc: 0.6838\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5915 - acc: 0.6891\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5896 - acc: 0.6899\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5860 - acc: 0.6933\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5853 - acc: 0.6941\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5829 - acc: 0.6911\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5824 - acc: 0.6887\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5848 - acc: 0.6938\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5836 - acc: 0.6869\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5778 - acc: 0.6950\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5807 - acc: 0.6968\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5755 - acc: 0.7007\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5773 - acc: 0.6948\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5752 - acc: 0.6998\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5745 - acc: 0.7011\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5840 - acc: 0.6957\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5818 - acc: 0.6941\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5729 - acc: 0.7015\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5674 - acc: 0.7033\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 1s 95us/step - loss: 0.5657 - acc: 0.7098\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 1s 88us/step - loss: 0.5658 - acc: 0.7082\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 1s 81us/step - loss: 0.5640 - acc: 0.7077\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 1s 77us/step - loss: 0.5649 - acc: 0.7099\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 1s 79us/step - loss: 0.5628 - acc: 0.7049\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 1s 79us/step - loss: 0.5635 - acc: 0.7117\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5664 - acc: 0.7067\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 1s 78us/step - loss: 0.5626 - acc: 0.7079\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 1s 83us/step - loss: 0.5610 - acc: 0.7126\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 1s 79us/step - loss: 0.5610 - acc: 0.7142\n",
      "3581/3581 [==============================] - 0s 119us/step\n",
      "7163/7163 [==============================] - 0s 47us/step\n",
      "Epoch 1/5\n",
      "7162/7162 [==============================] - 1s 148us/step - loss: 8.0860 - acc: 0.4983\n",
      "Epoch 2/5\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 4.2770 - acc: 0.5057\n",
      "Epoch 3/5\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.7949 - acc: 0.5066\n",
      "Epoch 4/5\n",
      "7162/7162 [==============================] - 0s 43us/step - loss: 0.7190 - acc: 0.5128\n",
      "Epoch 5/5\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.7059 - acc: 0.5193\n",
      "3582/3582 [==============================] - 0s 91us/step\n",
      "7162/7162 [==============================] - 0s 23us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 146us/step - loss: 6.3966 - acc: 0.5276\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 4.6368 - acc: 0.5812\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 2.7093 - acc: 0.5965\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 1.3728 - acc: 0.6203\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 0.9706 - acc: 0.6186\n",
      "3581/3581 [==============================] - 0s 96us/step\n",
      "7163/7163 [==============================] - 0s 25us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 152us/step - loss: 7.7319 - acc: 0.4914\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 6.6444 - acc: 0.5172\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 42us/step - loss: 5.0510 - acc: 0.5442\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - ETA: 0s - loss: 1.5119 - acc: 0.537 - 0s 41us/step - loss: 1.4126 - acc: 0.5366\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 41us/step - loss: 0.7676 - acc: 0.5168\n",
      "3581/3581 [==============================] - 0s 100us/step\n",
      "7163/7163 [==============================] - 0s 26us/step\n",
      "Epoch 1/10\n",
      "7162/7162 [==============================] - 1s 154us/step - loss: 1.2484 - acc: 0.5405\n",
      "Epoch 2/10\n",
      "7162/7162 [==============================] - 0s 43us/step - loss: 0.7112 - acc: 0.5512\n",
      "Epoch 3/10\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 0.6946 - acc: 0.5660\n",
      "Epoch 4/10\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 0.6883 - acc: 0.5599\n",
      "Epoch 5/10\n",
      "7162/7162 [==============================] - 0s 43us/step - loss: 0.6874 - acc: 0.5644\n",
      "Epoch 6/10\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.6846 - acc: 0.5761\n",
      "Epoch 7/10\n",
      "7162/7162 [==============================] - 0s 43us/step - loss: 0.6821 - acc: 0.5811\n",
      "Epoch 8/10\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.6799 - acc: 0.5814\n",
      "Epoch 9/10\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.6760 - acc: 0.5917\n",
      "Epoch 10/10\n",
      "7162/7162 [==============================] - 0s 42us/step - loss: 0.6742 - acc: 0.5940\n",
      "3582/3582 [==============================] - 0s 105us/step\n",
      "7162/7162 [==============================] - 0s 27us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 1s 167us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 43us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "3581/3581 [==============================] - 0s 116us/step\n",
      "7163/7163 [==============================] - 0s 28us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 1s 176us/step - loss: 2.4967 - acc: 0.5136\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.7652 - acc: 0.5181\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 48us/step - loss: 0.7233 - acc: 0.5252\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.7104 - acc: 0.5241\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.7030 - acc: 0.5425\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6919 - acc: 0.5616\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6833 - acc: 0.5742\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 0.6790 - acc: 0.5865\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 0.6772 - acc: 0.5912\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6730 - acc: 0.6150\n",
      "3581/3581 [==============================] - 0s 117us/step\n",
      "7163/7163 [==============================] - 0s 29us/step\n",
      "Epoch 1/50\n",
      "7162/7162 [==============================] - 1s 180us/step - loss: 8.0803 - acc: 0.4986\n",
      "Epoch 2/50\n",
      "7162/7162 [==============================] - 0s 49us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 3/50\n",
      "7162/7162 [==============================] - 0s 49us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 4/50\n",
      "7162/7162 [==============================] - 0s 48us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 5/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 6/50\n",
      "7162/7162 [==============================] - 0s 47us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 7/50\n",
      "7162/7162 [==============================] - 0s 46us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 8/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 9/50\n",
      "7162/7162 [==============================] - 0s 46us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 10/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 11/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 12/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 13/50\n",
      "7162/7162 [==============================] - 0s 46us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 14/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 15/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 16/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 17/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 18/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 19/50\n",
      "7162/7162 [==============================] - 0s 46us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 20/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 21/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 22/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 23/50\n",
      "7162/7162 [==============================] - 0s 46us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 24/50\n",
      "7162/7162 [==============================] - 0s 47us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 25/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 26/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 27/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 28/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 29/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 30/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 31/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 32/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 33/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 34/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 35/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 36/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 37/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 38/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 39/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 40/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 41/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 42/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 43/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 44/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 45/50\n",
      "7162/7162 [==============================] - 0s 47us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 46/50\n",
      "7162/7162 [==============================] - 0s 48us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 47/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 48/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 49/50\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 8.0883 - acc: 0.4982\n",
      "Epoch 50/50\n",
      "7162/7162 [==============================] - 0s 44us/step - loss: 8.0883 - acc: 0.4982\n",
      "3582/3582 [==============================] - 0s 122us/step\n",
      "7162/7162 [==============================] - 0s 29us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 183us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 48us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 0s 53us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 44us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 54us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 54us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 55us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 53us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 57us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 54us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 56us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 54us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 53us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 55us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 8.0872 - acc: 0.4983\n",
      "3581/3581 [==============================] - 0s 125us/step\n",
      "7163/7163 [==============================] - 0s 29us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 188us/step - loss: 8.0012 - acc: 0.4981\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 50us/step - loss: 1.8172 - acc: 0.4999\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 48us/step - loss: 0.6956 - acc: 0.5015\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 49us/step - loss: 0.6941 - acc: 0.5020: 0s - loss: 0.6899 - acc: \n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6939 - acc: 0.4962\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6937 - acc: 0.4943\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 49us/step - loss: 0.6938 - acc: 0.5031\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6946 - acc: 0.4966\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6922 - acc: 0.5023\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6931 - acc: 0.4907\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6922 - acc: 0.4931\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6950 - acc: 0.5033\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6885 - acc: 0.5068\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6909 - acc: 0.5084\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6906 - acc: 0.5003\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6904 - acc: 0.5096\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6896 - acc: 0.5188\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6839 - acc: 0.5195\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6858 - acc: 0.5168\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6844 - acc: 0.5209\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6816 - acc: 0.5327\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6800 - acc: 0.5348\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6799 - acc: 0.5407\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6815 - acc: 0.5358\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6804 - acc: 0.5368\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6760 - acc: 0.5440\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6747 - acc: 0.5461\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6731 - acc: 0.5533\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6719 - acc: 0.5569\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6729 - acc: 0.5640\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6685 - acc: 0.5789\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6677 - acc: 0.5735\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 49us/step - loss: 0.6633 - acc: 0.5847\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6638 - acc: 0.5784\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6611 - acc: 0.5883\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6614 - acc: 0.5838\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6546 - acc: 0.6017\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6535 - acc: 0.6006\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - ETA: 0s - loss: 0.6518 - acc: 0.602 - 0s 47us/step - loss: 0.6516 - acc: 0.6062\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 48us/step - loss: 0.6523 - acc: 0.6046\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6466 - acc: 0.6150\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6472 - acc: 0.6099\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6434 - acc: 0.6143\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6408 - acc: 0.6159\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 47us/step - loss: 0.6417 - acc: 0.6165\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6381 - acc: 0.6199\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 45us/step - loss: 0.6397 - acc: 0.6212\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6397 - acc: 0.6228\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 46us/step - loss: 0.6399 - acc: 0.6268\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 48us/step - loss: 0.6401 - acc: 0.6300\n",
      "3581/3581 [==============================] - 0s 130us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 0s 29us/step\n",
      "Epoch 1/5\n",
      "7162/7162 [==============================] - 1s 170us/step - loss: 3.0937 - acc: 0.5228\n",
      "Epoch 2/5\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 1.2748 - acc: 0.5186\n",
      "Epoch 3/5\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.8238 - acc: 0.5410\n",
      "Epoch 4/5\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.7445 - acc: 0.5455\n",
      "Epoch 5/5\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.7200 - acc: 0.5494\n",
      "3582/3582 [==============================] - 0s 119us/step\n",
      "7162/7162 [==============================] - 0s 13us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 164us/step - loss: 3.5376 - acc: 0.5098\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.7681 - acc: 0.5075\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.7079 - acc: 0.5040\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.7027 - acc: 0.5036\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 20us/step - loss: 0.7005 - acc: 0.4977\n",
      "3581/3581 [==============================] - 0s 118us/step\n",
      "7163/7163 [==============================] - 0s 14us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 171us/step - loss: 1.3280 - acc: 0.4892\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7086 - acc: 0.5017\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.7005 - acc: 0.5031\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6982 - acc: 0.4998\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 20us/step - loss: 0.6968 - acc: 0.5031\n",
      "3581/3581 [==============================] - 0s 122us/step\n",
      "7163/7163 [==============================] - 0s 14us/step\n",
      "Epoch 1/10\n",
      "7162/7162 [==============================] - 1s 178us/step - loss: 5.8225 - acc: 0.5163\n",
      "Epoch 2/10\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 2.1437 - acc: 0.5106\n",
      "Epoch 3/10\n",
      "7162/7162 [==============================] - 0s 26us/step - loss: 1.1437 - acc: 0.5336\n",
      "Epoch 4/10\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.8627 - acc: 0.5559\n",
      "Epoch 5/10\n",
      "7162/7162 [==============================] - 0s 41us/step - loss: 0.7586 - acc: 0.5669\n",
      "Epoch 6/10\n",
      "7162/7162 [==============================] - 0s 45us/step - loss: 0.7243 - acc: 0.5702\n",
      "Epoch 7/10\n",
      "7162/7162 [==============================] - 0s 33us/step - loss: 0.7099 - acc: 0.5734\n",
      "Epoch 8/10\n",
      "7162/7162 [==============================] - 0s 27us/step - loss: 0.6904 - acc: 0.5894\n",
      "Epoch 9/10\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6912 - acc: 0.5828\n",
      "Epoch 10/10\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6800 - acc: 0.5983\n",
      "3582/3582 [==============================] - 0s 133us/step\n",
      "7162/7162 [==============================] - 0s 14us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 1s 185us/step - loss: 4.0178 - acc: 0.5200\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 2.1455 - acc: 0.5710\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 1.2169 - acc: 0.5858\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.8839 - acc: 0.6094\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7583 - acc: 0.6207\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.7263 - acc: 0.6349\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.7057 - acc: 0.6268\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6681 - acc: 0.6532\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6783 - acc: 0.6366\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6626 - acc: 0.6441\n",
      "3581/3581 [==============================] - 0s 137us/step\n",
      "7163/7163 [==============================] - 0s 15us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 2s 214us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 25us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 39us/step - loss: 8.0287 - acc: 0.5019\n",
      "3581/3581 [==============================] - 1s 162us/step\n",
      "7163/7163 [==============================] - 0s 21us/step\n",
      "Epoch 1/50\n",
      "7162/7162 [==============================] - 1s 197us/step - loss: 1.1915 - acc: 0.5109\n",
      "Epoch 2/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.7161 - acc: 0.5029\n",
      "Epoch 3/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.7020 - acc: 0.4997\n",
      "Epoch 4/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6972 - acc: 0.4964\n",
      "Epoch 5/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6943 - acc: 0.4972\n",
      "Epoch 6/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6946 - acc: 0.4994\n",
      "Epoch 7/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5049\n",
      "Epoch 8/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6928 - acc: 0.5038\n",
      "Epoch 9/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5036\n",
      "Epoch 10/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6929 - acc: 0.5039\n",
      "Epoch 11/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.4999\n",
      "Epoch 12/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6922 - acc: 0.5036\n",
      "Epoch 13/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6916 - acc: 0.5040\n",
      "Epoch 14/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6924 - acc: 0.5031\n",
      "Epoch 15/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6920 - acc: 0.5039\n",
      "Epoch 16/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6923 - acc: 0.5032\n",
      "Epoch 17/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6922 - acc: 0.5032\n",
      "Epoch 18/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6922 - acc: 0.5032\n",
      "Epoch 19/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6926 - acc: 0.5036\n",
      "Epoch 20/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 21/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 22/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 23/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5027\n",
      "Epoch 24/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 25/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 26/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6925 - acc: 0.5028\n",
      "Epoch 27/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6931 - acc: 0.4966\n",
      "Epoch 28/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.4976\n",
      "Epoch 29/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 30/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 32/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 33/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 34/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 35/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 36/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 37/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.4964\n",
      "Epoch 38/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 39/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 40/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 41/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.4862\n",
      "Epoch 42/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 43/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 44/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 45/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 46/50\n",
      "7162/7162 [==============================] - 0s 23us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 47/50\n",
      "7162/7162 [==============================] - 0s 22us/step - loss: 0.6928 - acc: 0.5024\n",
      "Epoch 48/50\n",
      "7162/7162 [==============================] - 0s 24us/step - loss: 0.6928 - acc: 0.4973\n",
      "Epoch 49/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6940 - acc: 0.5031\n",
      "Epoch 50/50\n",
      "7162/7162 [==============================] - 0s 21us/step - loss: 0.6929 - acc: 0.5029\n",
      "3582/3582 [==============================] - 1s 143us/step\n",
      "7162/7162 [==============================] - 0s 15us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 202us/step - loss: 3.0439 - acc: 0.5433\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 37us/step - loss: 1.2032 - acc: 0.5752\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 33us/step - loss: 0.8731 - acc: 0.5792\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 29us/step - loss: 0.7680 - acc: 0.5972\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 37us/step - loss: 0.7342 - acc: 0.5929\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 32us/step - loss: 0.7045 - acc: 0.6004\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.6844 - acc: 0.6162\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6709 - acc: 0.6284\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 26us/step - loss: 0.6626 - acc: 0.6381\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6729 - acc: 0.6187\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.6556 - acc: 0.6360\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.6517 - acc: 0.6387\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 25us/step - loss: 0.6491 - acc: 0.6429\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6310 - acc: 0.6645\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6351 - acc: 0.6606\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6499 - acc: 0.6418\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6230 - acc: 0.6746\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6319 - acc: 0.6666\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6200 - acc: 0.6782\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6155 - acc: 0.6740\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6103 - acc: 0.6803\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6069 - acc: 0.6757\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.6070 - acc: 0.6781\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.6249 - acc: 0.6619\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6051 - acc: 0.6823\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6099 - acc: 0.6725\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.6039 - acc: 0.6770\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6009 - acc: 0.6810\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6171 - acc: 0.6696\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6016 - acc: 0.6856\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6029 - acc: 0.6795\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.6021 - acc: 0.6765\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6011 - acc: 0.6845\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5960 - acc: 0.6857\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5960 - acc: 0.6841\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5894 - acc: 0.6832\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5868 - acc: 0.6892\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6089 - acc: 0.6747\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5876 - acc: 0.6936\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5945 - acc: 0.6866\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5868 - acc: 0.6869\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.5851 - acc: 0.6917\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 30us/step - loss: 0.5827 - acc: 0.6923\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5870 - acc: 0.6913\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.5778 - acc: 0.6996\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.5817 - acc: 0.6978\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.5814 - acc: 0.6897\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.5861 - acc: 0.6906\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5871 - acc: 0.6867\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.5800 - acc: 0.6959\n",
      "3581/3581 [==============================] - 1s 151us/step\n",
      "7163/7163 [==============================] - 0s 14us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 1s 199us/step - loss: 4.2296 - acc: 0.5143\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 1.7226 - acc: 0.5337\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.9279 - acc: 0.5503\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7701 - acc: 0.5397\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7353 - acc: 0.5362\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7378 - acc: 0.5318\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7246 - acc: 0.5389\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.7180 - acc: 0.5500\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.7196 - acc: 0.5386\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7076 - acc: 0.5534\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7056 - acc: 0.5586\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.7202 - acc: 0.5383\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 24us/step - loss: 0.7146 - acc: 0.5362\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7021 - acc: 0.5496\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6981 - acc: 0.5545\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.7027 - acc: 0.5498\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.7013 - acc: 0.5494\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6915 - acc: 0.5718\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6995 - acc: 0.5555\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6908 - acc: 0.5745\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6903 - acc: 0.5748\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6918 - acc: 0.5676\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6878 - acc: 0.5742\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6885 - acc: 0.5766\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6861 - acc: 0.5813\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6798 - acc: 0.5925\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6778 - acc: 0.5953\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6799 - acc: 0.5896\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6820 - acc: 0.5861\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6714 - acc: 0.5925\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6676 - acc: 0.5947\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6615 - acc: 0.6059\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6617 - acc: 0.6028\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6646 - acc: 0.6039\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6478 - acc: 0.6252\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6461 - acc: 0.6243\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 25us/step - loss: 0.6488 - acc: 0.6264\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.6385 - acc: 0.6359\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 0s 25us/step - loss: 0.6375 - acc: 0.6432\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 23us/step - loss: 0.6426 - acc: 0.6328\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6348 - acc: 0.6500\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6322 - acc: 0.6543\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6243 - acc: 0.6581\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6206 - acc: 0.6704\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 21us/step - loss: 0.6242 - acc: 0.6658\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6153 - acc: 0.6708\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6151 - acc: 0.6739\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6139 - acc: 0.6728\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6060 - acc: 0.6782\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 22us/step - loss: 0.6052 - acc: 0.6797\n",
      "3581/3581 [==============================] - 1s 152us/step\n",
      "7163/7163 [==============================] - 0s 15us/step\n",
      "Epoch 1/5\n",
      "7162/7162 [==============================] - 1s 193us/step - loss: 6.3469 - acc: 0.5430\n",
      "Epoch 2/5\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 5.5564 - acc: 0.5398\n",
      "Epoch 3/5\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 2.4468 - acc: 0.5120\n",
      "Epoch 4/5\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 1.0176 - acc: 0.5306\n",
      "Epoch 5/5\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.8062 - acc: 0.5570\n",
      "3582/3582 [==============================] - 1s 146us/step\n",
      "7162/7162 [==============================] - 0s 9us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 195us/step - loss: 3.0082 - acc: 0.4815\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7974 - acc: 0.4917\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7144 - acc: 0.5051\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7053 - acc: 0.5052\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7050 - acc: 0.5054\n",
      "3581/3581 [==============================] - 1s 149us/step\n",
      "7163/7163 [==============================] - 0s 9us/step\n",
      "Epoch 1/5\n",
      "7163/7163 [==============================] - 1s 199us/step - loss: 6.5592 - acc: 0.5421\n",
      "Epoch 2/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 4.7153 - acc: 0.5688\n",
      "Epoch 3/5\n",
      "7163/7163 [==============================] - 0s 12us/step - loss: 1.3377 - acc: 0.5588\n",
      "Epoch 4/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.8208 - acc: 0.5283\n",
      "Epoch 5/5\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7526 - acc: 0.5221\n",
      "3581/3581 [==============================] - 1s 153us/step\n",
      "7163/7163 [==============================] - 0s 9us/step\n",
      "Epoch 1/10\n",
      "7162/7162 [==============================] - 1s 203us/step - loss: 3.7062 - acc: 0.5168\n",
      "Epoch 2/10\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 1.4217 - acc: 0.5008\n",
      "Epoch 3/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.9357 - acc: 0.5434\n",
      "Epoch 4/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.8211 - acc: 0.5465\n",
      "Epoch 5/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7838 - acc: 0.5398\n",
      "Epoch 6/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7592 - acc: 0.5328\n",
      "Epoch 7/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7277 - acc: 0.5531\n",
      "Epoch 8/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7249 - acc: 0.5454\n",
      "Epoch 9/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7181 - acc: 0.5549\n",
      "Epoch 10/10\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7073 - acc: 0.5653\n",
      "3582/3582 [==============================] - 1s 155us/step\n",
      "7162/7162 [==============================] - 0s 9us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 1s 209us/step - loss: 6.4463 - acc: 0.4779\n",
      "Epoch 2/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 2.1825 - acc: 0.5308\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7509 - acc: 0.5284\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7400 - acc: 0.5320\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7278 - acc: 0.5333\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7170 - acc: 0.5422\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7111 - acc: 0.5433\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7090 - acc: 0.5487\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7070 - acc: 0.5565\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6953 - acc: 0.5632\n",
      "3581/3581 [==============================] - 1s 163us/step\n",
      "7163/7163 [==============================] - 0s 9us/step\n",
      "Epoch 1/10\n",
      "7163/7163 [==============================] - 2s 214us/step - loss: 8.0290 - acc: 0.5017\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 3/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 4/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 5/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 6/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 7/10\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 8/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 9/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "Epoch 10/10\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 8.0287 - acc: 0.5019\n",
      "3581/3581 [==============================] - 1s 167us/step\n",
      "7163/7163 [==============================] - 0s 9us/step\n",
      "Epoch 1/50\n",
      "7162/7162 [==============================] - 2s 223us/step - loss: 4.3728 - acc: 0.5561\n",
      "Epoch 2/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.9300 - acc: 0.5331\n",
      "Epoch 3/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7354 - acc: 0.4913\n",
      "Epoch 4/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7214 - acc: 0.4987\n",
      "Epoch 5/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7176 - acc: 0.5052\n",
      "Epoch 6/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7155 - acc: 0.5053\n",
      "Epoch 7/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7152 - acc: 0.5053\n",
      "Epoch 8/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7145 - acc: 0.5015\n",
      "Epoch 9/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7134 - acc: 0.5074\n",
      "Epoch 10/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7129 - acc: 0.5064\n",
      "Epoch 11/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7124 - acc: 0.5075\n",
      "Epoch 12/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7127 - acc: 0.4999\n",
      "Epoch 13/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7122 - acc: 0.5075\n",
      "Epoch 14/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7117 - acc: 0.4997\n",
      "Epoch 15/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7117 - acc: 0.5091\n",
      "Epoch 16/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7111 - acc: 0.5091\n",
      "Epoch 17/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7106 - acc: 0.4971\n",
      "Epoch 18/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7103 - acc: 0.5106\n",
      "Epoch 19/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7102 - acc: 0.5060\n",
      "Epoch 20/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7100 - acc: 0.5131\n",
      "Epoch 21/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7099 - acc: 0.5135\n",
      "Epoch 22/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7095 - acc: 0.5156\n",
      "Epoch 23/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7097 - acc: 0.5021\n",
      "Epoch 24/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7094 - acc: 0.5154\n",
      "Epoch 25/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7088 - acc: 0.5103\n",
      "Epoch 26/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7086 - acc: 0.5163\n",
      "Epoch 27/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7086 - acc: 0.5166\n",
      "Epoch 28/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7087 - acc: 0.5182\n",
      "Epoch 29/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7085 - acc: 0.5188\n",
      "Epoch 30/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7081 - acc: 0.5204\n",
      "Epoch 31/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7082 - acc: 0.5208\n",
      "Epoch 32/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7074 - acc: 0.5209\n",
      "Epoch 33/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7074 - acc: 0.5225\n",
      "Epoch 34/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7070 - acc: 0.5211\n",
      "Epoch 35/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7061 - acc: 0.5233\n",
      "Epoch 36/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7049 - acc: 0.5250\n",
      "Epoch 37/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.7048 - acc: 0.5239\n",
      "Epoch 38/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7055 - acc: 0.5246\n",
      "Epoch 39/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7039 - acc: 0.5269\n",
      "Epoch 40/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7041 - acc: 0.5314\n",
      "Epoch 41/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7030 - acc: 0.5343\n",
      "Epoch 42/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7034 - acc: 0.5376\n",
      "Epoch 43/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7026 - acc: 0.5412\n",
      "Epoch 44/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.7002 - acc: 0.5486\n",
      "Epoch 45/50\n",
      "7162/7162 [==============================] - 0s 14us/step - loss: 0.6989 - acc: 0.5571\n",
      "Epoch 46/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.6997 - acc: 0.5662\n",
      "Epoch 47/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.6974 - acc: 0.5733\n",
      "Epoch 48/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.6929 - acc: 0.5832\n",
      "Epoch 49/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.6907 - acc: 0.5902\n",
      "Epoch 50/50\n",
      "7162/7162 [==============================] - 0s 13us/step - loss: 0.6878 - acc: 0.5951\n",
      "3582/3582 [==============================] - 1s 174us/step\n",
      "7162/7162 [==============================] - 0s 10us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 2s 226us/step - loss: 1.2419 - acc: 0.5225\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7213 - acc: 0.5587\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6980 - acc: 0.5615\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6923 - acc: 0.5685\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6906 - acc: 0.5660\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6897 - acc: 0.5753\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6884 - acc: 0.5781\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6871 - acc: 0.5834\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6858 - acc: 0.5851\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6846 - acc: 0.5876\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6836 - acc: 0.5884\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6819 - acc: 0.5894\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6805 - acc: 0.5889\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6786 - acc: 0.5943\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6777 - acc: 0.5901\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6749 - acc: 0.6007\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6733 - acc: 0.6039\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6717 - acc: 0.6039\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6692 - acc: 0.6070\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6679 - acc: 0.6129\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6670 - acc: 0.6171\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6652 - acc: 0.6197\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6629 - acc: 0.6207\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6620 - acc: 0.6263\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6601 - acc: 0.6298\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6589 - acc: 0.6282\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6561 - acc: 0.6333\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6551 - acc: 0.6335\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6538 - acc: 0.6365\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6500 - acc: 0.6451\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6480 - acc: 0.6465\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6449 - acc: 0.6500\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6455 - acc: 0.6448\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6428 - acc: 0.6521\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6385 - acc: 0.6531\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6379 - acc: 0.6532\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6380 - acc: 0.6542\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6332 - acc: 0.6568\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6333 - acc: 0.6594\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6299 - acc: 0.6598\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6312 - acc: 0.6580\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6279 - acc: 0.6602\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6251 - acc: 0.6629\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6234 - acc: 0.6642\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6230 - acc: 0.6616\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6216 - acc: 0.6640\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6197 - acc: 0.6638\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6226 - acc: 0.6615\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6226 - acc: 0.6659\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6174 - acc: 0.6651\n",
      "3581/3581 [==============================] - 1s 177us/step\n",
      "7163/7163 [==============================] - 0s 9us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 2s 228us/step - loss: 5.9790 - acc: 0.5580\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 5.5883 - acc: 0.5714\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 5.0205 - acc: 0.5970\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 4.6832 - acc: 0.6108\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 4.4380 - acc: 0.6179\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 4.1937 - acc: 0.6136\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 3.6703 - acc: 0.6189\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 3.1087 - acc: 0.6130\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 2.3306 - acc: 0.6080\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 1.6574 - acc: 0.6147\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 1.1832 - acc: 0.6125\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.9370 - acc: 0.6207\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.8742 - acc: 0.6186\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.8482 - acc: 0.6186\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7669 - acc: 0.6388\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7711 - acc: 0.6263\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7556 - acc: 0.6333\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7065 - acc: 0.6592\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7462 - acc: 0.6303\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7231 - acc: 0.6400\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7243 - acc: 0.6369\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.7122 - acc: 0.6351\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7455 - acc: 0.6274\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6893 - acc: 0.6501\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7347 - acc: 0.6331\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7510 - acc: 0.6257\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6917 - acc: 0.6496\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6672 - acc: 0.6587\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6693 - acc: 0.6574\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6702 - acc: 0.6613\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7052 - acc: 0.6369\n",
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6565 - acc: 0.6573\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6552 - acc: 0.6567\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6864 - acc: 0.6420\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6681 - acc: 0.6485\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6537 - acc: 0.6584\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6417 - acc: 0.6620\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6593 - acc: 0.6496\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6998 - acc: 0.6340\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6621 - acc: 0.6517\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6619 - acc: 0.6541\n",
      "Epoch 42/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6415 - acc: 0.6612\n",
      "Epoch 43/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.7679 - acc: 0.6172\n",
      "Epoch 44/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6349 - acc: 0.6656\n",
      "Epoch 45/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.6514\n",
      "Epoch 46/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6440 - acc: 0.6598\n",
      "Epoch 47/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.6513\n",
      "Epoch 48/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6694 - acc: 0.6450\n",
      "Epoch 49/50\n",
      "7163/7163 [==============================] - 0s 14us/step - loss: 0.6313 - acc: 0.6676\n",
      "Epoch 50/50\n",
      "7163/7163 [==============================] - 0s 13us/step - loss: 0.6877 - acc: 0.6393\n",
      "3581/3581 [==============================] - 1s 181us/step\n",
      "7163/7163 [==============================] - 0s 10us/step\n",
      "Epoch 1/50\n",
      "10744/10744 [==============================] - 3s 265us/step - loss: 1.2732 - acc: 0.5028\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10744/10744 [==============================] - 1s 133us/step - loss: 0.6860 - acc: 0.5455\n",
      "Epoch 3/50\n",
      "10744/10744 [==============================] - 1s 123us/step - loss: 0.6702 - acc: 0.5940\n",
      "Epoch 4/50\n",
      "10744/10744 [==============================] - 1s 129us/step - loss: 0.6576 - acc: 0.6158\n",
      "Epoch 5/50\n",
      "10744/10744 [==============================] - 1s 127us/step - loss: 0.6448 - acc: 0.6372\n",
      "Epoch 6/50\n",
      "10744/10744 [==============================] - 1s 122us/step - loss: 0.6286 - acc: 0.6579\n",
      "Epoch 7/50\n",
      "10744/10744 [==============================] - 1s 124us/step - loss: 0.6182 - acc: 0.6683 1s - l\n",
      "Epoch 8/50\n",
      "10744/10744 [==============================] - 1s 123us/step - loss: 0.6125 - acc: 0.6742\n",
      "Epoch 9/50\n",
      "10744/10744 [==============================] - 1s 122us/step - loss: 0.6072 - acc: 0.6787\n",
      "Epoch 10/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.6066 - acc: 0.6749\n",
      "Epoch 11/50\n",
      "10744/10744 [==============================] - ETA: 0s - loss: 0.5997 - acc: 0.686 - 1s 113us/step - loss: 0.5999 - acc: 0.6860\n",
      "Epoch 12/50\n",
      "10744/10744 [==============================] - 1s 111us/step - loss: 0.5971 - acc: 0.6861\n",
      "Epoch 13/50\n",
      "10744/10744 [==============================] - 1s 113us/step - loss: 0.6026 - acc: 0.6915\n",
      "Epoch 14/50\n",
      "10744/10744 [==============================] - 1s 114us/step - loss: 0.5936 - acc: 0.6875\n",
      "Epoch 15/50\n",
      "10744/10744 [==============================] - 1s 113us/step - loss: 0.5921 - acc: 0.6862\n",
      "Epoch 16/50\n",
      "10744/10744 [==============================] - 1s 114us/step - loss: 0.5878 - acc: 0.6917\n",
      "Epoch 17/50\n",
      "10744/10744 [==============================] - 1s 114us/step - loss: 0.5858 - acc: 0.6934\n",
      "Epoch 18/50\n",
      "10744/10744 [==============================] - 1s 113us/step - loss: 0.5856 - acc: 0.6984\n",
      "Epoch 19/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5854 - acc: 0.7027\n",
      "Epoch 20/50\n",
      "10744/10744 [==============================] - 1s 114us/step - loss: 0.5791 - acc: 0.7013\n",
      "Epoch 21/50\n",
      "10744/10744 [==============================] - 1s 113us/step - loss: 0.5797 - acc: 0.6975\n",
      "Epoch 22/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5777 - acc: 0.7010\n",
      "Epoch 23/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5775 - acc: 0.7020\n",
      "Epoch 24/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5761 - acc: 0.7020\n",
      "Epoch 25/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5738 - acc: 0.7032\n",
      "Epoch 26/50\n",
      "10744/10744 [==============================] - 1s 128us/step - loss: 0.5717 - acc: 0.7067\n",
      "Epoch 27/50\n",
      "10744/10744 [==============================] - 1s 119us/step - loss: 0.5689 - acc: 0.7077\n",
      "Epoch 28/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.5683 - acc: 0.7059\n",
      "Epoch 29/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.5646 - acc: 0.7116\n",
      "Epoch 30/50\n",
      "10744/10744 [==============================] - 1s 120us/step - loss: 0.5611 - acc: 0.7120\n",
      "Epoch 31/50\n",
      "10744/10744 [==============================] - 1s 120us/step - loss: 0.5611 - acc: 0.7137\n",
      "Epoch 32/50\n",
      "10744/10744 [==============================] - 1s 113us/step - loss: 0.5622 - acc: 0.7135\n",
      "Epoch 33/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5608 - acc: 0.7166\n",
      "Epoch 34/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.5582 - acc: 0.7179\n",
      "Epoch 35/50\n",
      "10744/10744 [==============================] - 1s 123us/step - loss: 0.5577 - acc: 0.7238\n",
      "Epoch 36/50\n",
      "10744/10744 [==============================] - 1s 124us/step - loss: 0.5571 - acc: 0.7169\n",
      "Epoch 37/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.5582 - acc: 0.7158\n",
      "Epoch 38/50\n",
      "10744/10744 [==============================] - 1s 112us/step - loss: 0.5566 - acc: 0.7198\n",
      "Epoch 39/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5567 - acc: 0.7160\n",
      "Epoch 40/50\n",
      "10744/10744 [==============================] - 1s 121us/step - loss: 0.5554 - acc: 0.7173\n",
      "Epoch 41/50\n",
      "10744/10744 [==============================] - 1s 118us/step - loss: 0.5529 - acc: 0.7187\n",
      "Epoch 42/50\n",
      "10744/10744 [==============================] - 1s 114us/step - loss: 0.5512 - acc: 0.7205\n",
      "Epoch 43/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5557 - acc: 0.7168\n",
      "Epoch 44/50\n",
      "10744/10744 [==============================] - 1s 112us/step - loss: 0.5511 - acc: 0.7213\n",
      "Epoch 45/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5503 - acc: 0.7239\n",
      "Epoch 46/50\n",
      "10744/10744 [==============================] - 1s 115us/step - loss: 0.5535 - acc: 0.7201\n",
      "Epoch 47/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5496 - acc: 0.7252\n",
      "Epoch 48/50\n",
      "10744/10744 [==============================] - 1s 117us/step - loss: 0.5478 - acc: 0.7196\n",
      "Epoch 49/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5504 - acc: 0.7203\n",
      "Epoch 50/50\n",
      "10744/10744 [==============================] - 1s 116us/step - loss: 0.5464 - acc: 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001ECF4EEEBE0>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'batch_size': [10, 20, 50, 100], 'epochs': [5, 10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=mortality_model)   \n",
    "batch_size = [10,20,50,100]\n",
    "epochs = [5,10,50]\n",
    "parameters = {'batch_size': batch_size,'epochs': epochs}\n",
    "clf = GridSearchCV(model,parameters)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7052308276159743 {'batch_size': 10, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_,clf.best_params_)\n",
    "\n",
    "#means = clf.cv_results_['mean_test_score']\n",
    "#paramters = clf.cv_results_['params']\n",
    "#for mean, parameter in zip(means,parameters):\n",
    "#    print(mean, parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7162/7162 [==============================] - 2s 337us/step - loss: 7.9399 - acc: 0.5018\n",
      "Epoch 2/50\n",
      "7162/7162 [==============================] - 1s 116us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 3/50\n",
      "7162/7162 [==============================] - 1s 117us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 4/50\n",
      "7162/7162 [==============================] - 1s 111us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 5/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 6/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 7/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 8/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 9/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 10/50\n",
      "7162/7162 [==============================] - 1s 118us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 11/50\n",
      "7162/7162 [==============================] - 1s 117us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 12/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 13/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 14/50\n",
      "7162/7162 [==============================] - 1s 116us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 15/50\n",
      "7162/7162 [==============================] - 1s 121us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 16/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 17/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 18/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 19/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 20/50\n",
      "7162/7162 [==============================] - 1s 117us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 21/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 22/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 23/50\n",
      "7162/7162 [==============================] - 1s 116us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 24/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 25/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 26/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 27/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 28/50\n",
      "7162/7162 [==============================] - 1s 115us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 29/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 30/50\n",
      "7162/7162 [==============================] - 1s 111us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 31/50\n",
      "7162/7162 [==============================] - 1s 115us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 32/50\n",
      "7162/7162 [==============================] - 1s 111us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 33/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 34/50\n",
      "7162/7162 [==============================] - 1s 120us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 35/50\n",
      "7162/7162 [==============================] - 1s 124us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 36/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 37/50\n",
      "7162/7162 [==============================] - 1s 116us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 38/50\n",
      "7162/7162 [==============================] - 1s 116us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 39/50\n",
      "7162/7162 [==============================] - 1s 115us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 40/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 41/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 42/50\n",
      "7162/7162 [==============================] - 1s 111us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 43/50\n",
      "7162/7162 [==============================] - 1s 114us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 44/50\n",
      "7162/7162 [==============================] - 1s 117us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 45/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 46/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 47/50\n",
      "7162/7162 [==============================] - 1s 110us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 48/50\n",
      "7162/7162 [==============================] - 1s 113us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 49/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "Epoch 50/50\n",
      "7162/7162 [==============================] - 1s 112us/step - loss: 7.9423 - acc: 0.5018\n",
      "3582/3582 [==============================] - 1s 271us/step\n",
      "7162/7162 [==============================] - 1s 79us/step\n",
      "Epoch 1/50\n",
      "7163/7163 [==============================] - 2s 341us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 2/50\n",
      "7163/7163 [==============================] - 1s 115us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 3/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 4/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 5/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 6/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 7/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 8/50\n",
      "7163/7163 [==============================] - 1s 118us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 9/50\n",
      "7163/7163 [==============================] - 1s 113us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 10/50\n",
      "7163/7163 [==============================] - 1s 116us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 11/50\n",
      "7163/7163 [==============================] - 1s 113us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 12/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 13/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 14/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 15/50\n",
      "7163/7163 [==============================] - 1s 117us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 16/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 17/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 18/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 19/50\n",
      "7163/7163 [==============================] - 1s 109us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 20/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 21/50\n",
      "7163/7163 [==============================] - 1s 109us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 22/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 23/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 24/50\n",
      "7163/7163 [==============================] - 1s 110us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 25/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 26/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 27/50\n",
      "7163/7163 [==============================] - 1s 116us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 28/50\n",
      "7163/7163 [==============================] - 1s 113us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 29/50\n",
      "7163/7163 [==============================] - 1s 114us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 30/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 31/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 33/50\n",
      "7163/7163 [==============================] - 1s 113us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 34/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 35/50\n",
      "7163/7163 [==============================] - 1s 111us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 36/50\n",
      "7163/7163 [==============================] - 1s 112us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 37/50\n",
      "7163/7163 [==============================] - 1s 110us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 38/50\n",
      "7163/7163 [==============================] - 1s 113us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 39/50\n",
      "7163/7163 [==============================] - 1s 122us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 40/50\n",
      "7163/7163 [==============================] - 1s 122us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 41/50\n",
      "7163/7163 [==============================] - 1s 115us/step - loss: 8.0872 - acc: 0.4983\n",
      "Epoch 42/50\n",
      "2700/7163 [==========>...................] - ETA: 0s - loss: 8.1486 - acc: 0.4944"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-90246bacb18f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SGD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RMSprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Adagrad'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Adamax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Nadam'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ian\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mortality_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14, input_dim=20, activation='relu'))\n",
    "    model.add(Dense(7,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=mortality_model,epochs=50,batch_size=10)  \n",
    "parameters = {'optimizer':['SGD','RMSprop','Adagrad','Adam','Adamax','Nadam']}\n",
    "clf = GridSearchCV(model,parameters)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
